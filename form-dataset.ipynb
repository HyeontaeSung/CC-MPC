{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polyphonic-exhaust",
   "metadata": {},
   "source": [
    "Create (train, val, test) set from dataset composed of multiple data `.pkl` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "subsequent-vaccine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_13-12-34_dataset.pkl',\n",
       " '/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_12-44-33_dataset.pkl',\n",
       " '/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_13-26-49_dataset.pkl',\n",
       " '/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_12-58-34_dataset.pkl',\n",
       " '/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_13-40-55_dataset.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import dill\n",
    "import random\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collect.generate.scene.v3.trajectron_scene import augment_scene\n",
    "\n",
    "DATADIR = 'carla_v3_0_1_dataset'\n",
    "# DATADIR = 'out'\n",
    "[os.path.abspath(path) for path in glob(f\"{ DATADIR }/*_dataset.pkl\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-promotion",
   "metadata": {},
   "source": [
    "Copy the output array into the next Jupyter notebook cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "crazy-things",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ['/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_13-12-34_dataset.pkl',\n",
    " '/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_12-44-33_dataset.pkl',\n",
    " '/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_13-26-49_dataset.pkl',\n",
    " '/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_12-58-34_dataset.pkl',\n",
    " '/home/fireofearth/code/robotics/carla-collect/carla_v3_0_1_dataset/20210719_13-40-55_dataset.pkl']\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-equipment",
   "metadata": {},
   "source": [
    "## Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "orange-booth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(ds[0], 'rb') as f:\n",
    "    env = dill.load(f, encoding='latin1')\n",
    "len(env.scenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-venture",
   "metadata": {},
   "source": [
    "## Creating (train, val, test) sets from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adapted-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pkl_to_train_set = 1\n",
    "val_set_idx  = 3\n",
    "test_set_idx = 4\n",
    "val_set_size = 30\n",
    "test_set_size = 30\n",
    "version_label = \"v3_0_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "necessary-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming train set\n",
      "Got 209 scenes\n",
      "Augmenting scenes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eed90b4397547b1b50a6baa5f8fdacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=209.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shuffling scenes\n",
      "Saving train set\n",
      "Saving val set\n",
      "Has 203 scenes, selecting 30 of them\n",
      "Saving test set\n",
      "Has 211 scenes, selecting 30 of them\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "print(\"Forming train set\")\n",
    "with open(ds[0], 'rb') as f:\n",
    "    env = dill.load(f, encoding='latin1')\n",
    "for dataset in ds[1:n_pkl_to_train_set]:\n",
    "    with open(dataset, 'rb') as f:\n",
    "        env2 = dill.load(f, encoding='latin1')\n",
    "    env.scenes.extend(env2.scenes)\n",
    "print(f\"Got {len(env.scenes)} scenes\")\n",
    "\n",
    "print(\"Augmenting scenes\")\n",
    "for scene in tqdm(env.scenes):\n",
    "    scene.augmented = list()\n",
    "    angles = np.arange(0, 360, 15)\n",
    "    for angle in angles:\n",
    "        scene.augmented.append(augment_scene(scene, angle))\n",
    "\n",
    "print(\"Shuffling scenes\")\n",
    "random.shuffle(env.scenes)\n",
    "random.shuffle(env.scenes)\n",
    "        \n",
    "print(\"Saving train set\")\n",
    "savepath = f\"{ DATADIR }/carla_train_{ version_label }_full.pkl\"\n",
    "with open(savepath, 'wb') as f:\n",
    "    dill.dump(env, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Saving val set\")\n",
    "savepath = f\"{ DATADIR }/carla_val_{ version_label }_full.pkl\"\n",
    "if val_set_size is None:\n",
    "    shutil.copyfile(ds[val_set_idx], os.path.abspath(savepath))\n",
    "else:\n",
    "    with open(ds[val_set_idx], 'rb') as f:\n",
    "        env = dill.load(f, encoding='latin1')\n",
    "    print(f\"Has {len(env.scenes)} scenes, selecting {val_set_size} of them\")\n",
    "    random.shuffle(env.scenes)\n",
    "    env.scenes = env.scenes[:val_set_size]\n",
    "    with open(savepath, 'wb') as f:\n",
    "        dill.dump(env, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Saving test set\")\n",
    "savepath = f\"{ DATADIR }/carla_test_{ version_label }_full.pkl\"\n",
    "if test_set_size is None:\n",
    "    shutil.copyfile(ds[test_set_idx], os.path.abspath(savepath))\n",
    "else:\n",
    "    with open(ds[test_set_idx], 'rb') as f:\n",
    "        env = dill.load(f, encoding='latin1')\n",
    "    print(f\"Has {len(env.scenes)} scenes, selecting {test_set_size} of them\")\n",
    "    random.shuffle(env.scenes)\n",
    "    env.scenes = env.scenes[:test_set_size]\n",
    "    with open(savepath, 'wb') as f:\n",
    "        dill.dump(env, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-aurora",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "civilian-matthew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming train set\n",
      "Got 12 scenes\n",
      "Augmenting scenes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09be3003fd9545b6ba4e37c58d5c3f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving train set\n"
     ]
    }
   ],
   "source": [
    "# just create train set\n",
    "print(\"Forming train set\")\n",
    "with open(ds[0], 'rb') as f:\n",
    "    env = dill.load(f, encoding='latin1')\n",
    "for dataset in ds[1:n_pkl_to_train_set]:\n",
    "    with open(dataset, 'rb') as f:\n",
    "        env2 = dill.load(f, encoding='latin1')\n",
    "    env.scenes.extend(env2.scenes)\n",
    "print(f\"Got {len(env.scenes)} scenes\")\n",
    "\n",
    "print(\"Augmenting scenes\")\n",
    "for scene in tqdm(env.scenes):\n",
    "    scene.augmented = list()\n",
    "    angles = np.arange(0, 360, 15)\n",
    "    for angle in angles:\n",
    "        scene.augmented.append(augment_scene(scene, angle))\n",
    "\n",
    "print(\"Saving train set\")\n",
    "savepath = f\"{ DATADIR }/carla_train_{ version_label }_full.pkl\"\n",
    "with open(savepath, 'wb') as f:\n",
    "    dill.dump(env, f, protocol=dill.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-petroleum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Trajectron++)",
   "language": "python",
   "name": "trajectronpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
