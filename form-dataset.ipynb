{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "random-nepal",
   "metadata": {},
   "source": [
    "Create (train, val, test) set from dataset composed of multiple data `.pkl` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_13-22-26_dataset.pkl',\n",
       " '/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_13-37-12_dataset.pkl',\n",
       " '/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_14-21-59_dataset.pkl',\n",
       " '/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_13-52-06_dataset.pkl',\n",
       " '/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_14-07-01_dataset.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import dill\n",
    "import random\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collect.generate.scene.trajectron_scene import augment_scene\n",
    "\n",
    "DATADIR = 'carla_v2_2_dataset'\n",
    "[os.path.abspath(path) for path in glob(f\"{ DATADIR }/*_dataset.pkl\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-wallet",
   "metadata": {},
   "source": [
    "Copy the output array into the next Jupyter notebook cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valid-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ['/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_13-22-26_dataset.pkl',\n",
    " '/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_13-37-12_dataset.pkl',\n",
    " '/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_14-21-59_dataset.pkl',\n",
    " '/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_13-52-06_dataset.pkl',\n",
    " '/home/fireofearth/code/robotics/carla-collect/carla_v2_2_dataset/20210714_14-07-01_dataset.pkl']\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-commonwealth",
   "metadata": {},
   "source": [
    "## Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "registered-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(ds[0], 'rb') as f:\n",
    "    env = dill.load(f, encoding='latin1')\n",
    "len(env.scenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-geneva",
   "metadata": {},
   "source": [
    "## Creating (train, val, test) sets from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "appreciated-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pkl_to_train_set = 1\n",
    "val_set_idx  = 3\n",
    "test_set_idx = 4\n",
    "val_set_size = 30\n",
    "test_set_size = 30\n",
    "version_label = \"v2_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "suspected-mitchell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forming train set\n",
      "Got 212 scenes\n",
      "Augmenting scenes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06c97ac898547da99c8604ce1aad5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=212.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shuffling scenes\n",
      "Saving train set\n",
      "Saving val set\n",
      "Has 220 scenes, selecting 30 of them\n",
      "Saving test set\n",
      "Has 227 scenes, selecting 30 of them\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "print(\"Forming train set\")\n",
    "with open(ds[0], 'rb') as f:\n",
    "    env = dill.load(f, encoding='latin1')\n",
    "for dataset in ds[1:n_pkl_to_train_set]:\n",
    "    with open(dataset, 'rb') as f:\n",
    "        env2 = dill.load(f, encoding='latin1')\n",
    "    env.scenes.extend(env2.scenes)\n",
    "print(f\"Got {len(env.scenes)} scenes\")\n",
    "\n",
    "print(\"Augmenting scenes\")\n",
    "for scene in tqdm(env.scenes):\n",
    "    scene.augmented = list()\n",
    "    angles = np.arange(0, 360, 15)\n",
    "    for angle in angles:\n",
    "        scene.augmented.append(augment_scene(scene, angle))\n",
    "\n",
    "print(\"Shuffling scenes\")\n",
    "random.shuffle(env.scenes)\n",
    "random.shuffle(env.scenes)\n",
    "        \n",
    "print(\"Saving train set\")\n",
    "savepath = f\"{ DATADIR }/carla_train_{ version_label }_full.pkl\"\n",
    "with open(savepath, 'wb') as f:\n",
    "    dill.dump(env, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Saving val set\")\n",
    "savepath = f\"{ DATADIR }/carla_val_{ version_label }_full.pkl\"\n",
    "if val_set_size is None:\n",
    "    shutil.copyfile(ds[val_set_idx], os.path.abspath(savepath))\n",
    "else:\n",
    "    with open(ds[val_set_idx], 'rb') as f:\n",
    "        env = dill.load(f, encoding='latin1')\n",
    "    print(f\"Has {len(env.scenes)} scenes, selecting {val_set_size} of them\")\n",
    "    random.shuffle(env.scenes)\n",
    "    env.scenes = env.scenes[:val_set_size]\n",
    "    with open(savepath, 'wb') as f:\n",
    "        dill.dump(env, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Saving test set\")\n",
    "savepath = f\"{ DATADIR }/carla_test_{ version_label }_full.pkl\"\n",
    "if test_set_size is None:\n",
    "    shutil.copyfile(ds[test_set_idx], os.path.abspath(savepath))\n",
    "else:\n",
    "    with open(ds[test_set_idx], 'rb') as f:\n",
    "        env = dill.load(f, encoding='latin1')\n",
    "    print(f\"Has {len(env.scenes)} scenes, selecting {test_set_size} of them\")\n",
    "    random.shuffle(env.scenes)\n",
    "    env.scenes = env.scenes[:test_set_size]\n",
    "    with open(savepath, 'wb') as f:\n",
    "        dill.dump(env, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-carbon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Trajectron++)",
   "language": "python",
   "name": "trajectronpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
